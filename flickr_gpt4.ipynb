{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import random\n",
    "import base64\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from PIL import Image\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aryankargwal/miniconda3/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1614: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "dataset = load_dataset(\"mozilla/flickr30k-transformed-captions-gpt4o\", split='test')\n",
    "\n",
    "# Load a pre-trained model for sentence embeddings\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Randomly select 500 samples\n",
    "random_samples = random.sample(range(len(dataset)), 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to encode image data to base64\n",
    "def encode_image(image):\n",
    "    buffered = BytesIO()\n",
    "    image.save(buffered, format=\"JPEG\")  # Save the image to a buffer\n",
    "    return base64.b64encode(buffered.getvalue()).decode('utf-8')\n",
    "\n",
    "def query_model(instruction, image):\n",
    "    system_prompt = (\n",
    "        \"Generate a detailed description of the image in approximately 40 words. \"\n",
    "        \"Include key elements and vivid details, and ensure it accurately reflects the content of the image.\"\n",
    "    )\n",
    "    \n",
    "    full_instruction = f\"{system_prompt}\"\n",
    "    \n",
    "    # Encode the image data to base64\n",
    "    base64_image = encode_image(image)\n",
    "    \n",
    "    url = \"https://proxy.tune.app/chat/completions\"\n",
    "    headers = {\n",
    "        \"Authorization\": \"YOUR_TUNE_API_KEY\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    payload = {\n",
    "        \"temperature\": 0.4,\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": full_instruction},\n",
    "                    {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"}}\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        \"model\": \"mistral/pixtral-12B-2409\",\n",
    "        \"stream\": False,\n",
    "        \"frequency_penalty\": 0.2,\n",
    "        \"max_tokens\": 300\n",
    "    }\n",
    "    try:\n",
    "        response = requests.post(url, headers=headers, json=payload)\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    except Exception as e:\n",
    "        print(f\"Error querying model: {e}\")\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists\n",
    "valid_samples = []\n",
    "similarity_scores = []\n",
    "gpt_scores_list = []\n",
    "\n",
    "# Process dataset and accumulate results\n",
    "for idx in random_samples:  # Use idx to get each sample\n",
    "    sample = dataset[idx]  # Access the sample using the index\n",
    "    image = sample['image']  # Directly use the image object\n",
    "    filename = sample['filename']  # Ensure this key is correct for filename\n",
    "    \n",
    "    # Query the model\n",
    "    response = query_model(\"Describe this image\", image)\n",
    "    model_output = response.get(\"choices\", [{}])[0].get(\"message\", {}).get(\"content\", \"\").strip()\n",
    "    \n",
    "    # Extract Real captions\n",
    "    reference_outputs = sample['original_alt_text']  # Ensure this key is correct for captions\n",
    "    \n",
    "    # Compute embeddings for reference outputs and model output\n",
    "    reference_embeddings = model.encode(reference_outputs, convert_to_tensor=True)\n",
    "    model_embedding = model.encode(model_output, convert_to_tensor=True)\n",
    "    \n",
    "    # Calculate cosine similarity\n",
    "    similarity_scores = [util.pytorch_cos_sim(model_embedding, ref_emb).item() for ref_emb in reference_embeddings]\n",
    "    \n",
    "    # Extract GPT-4 Caption\n",
    "    gpt_output = sample['alt_text']  # Ensure this key is correct for captions\n",
    "    \n",
    "    # Compute embedding for GPT-4 output\n",
    "    gpt_embedding = model.encode(gpt_output, convert_to_tensor=True)\n",
    "    \n",
    "    # Ensure the GPT embedding is a 2D tensor for batch operations\n",
    "    if gpt_embedding.dim() == 1:\n",
    "        gpt_embedding = gpt_embedding.unsqueeze(0)  # Add batch dimension if needed\n",
    "    \n",
    "    # Calculate cosine similarity for each reference caption\n",
    "    gpt_scores = [util.pytorch_cos_sim(gpt_embedding, ref_emb.unsqueeze(0)).item() for ref_emb in reference_embeddings]\n",
    "    \n",
    "    # Calculate win rates based on a threshold\n",
    "    model_win_rate = sum(score > 0.8 for score in similarity_scores) / len(similarity_scores) if len(similarity_scores) > 0 else 0\n",
    "    gpt_win_rate = sum(score > 0.8 for score in gpt_scores) / len(gpt_scores) if len(gpt_scores) > 0 else 0\n",
    "    \n",
    "    # Collect the results\n",
    "    valid_samples.append({\n",
    "        \"filename\": filename,\n",
    "        \"model_output\": model_output,\n",
    "        \"reference_outputs\": reference_outputs,\n",
    "        \"similarity_scores\": similarity_scores,\n",
    "        \"GPT similarity score\": gpt_scores\n",
    "    })\n",
    "    gpt_scores_list.extend(gpt_scores)  # Store GPT-4 scores for final metrics calculations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   win_rate  top_1_score  top_5_average_score  top_10_average_score\n",
      "0       0.0     0.336796             0.279737                     0\n",
      "   win_rate  top_1_score  top_5_average_score  top_10_average_score\n",
      "0    0.0506     0.987752             0.978322              0.966494\n"
     ]
    }
   ],
   "source": [
    "# Calculate win rate for model\n",
    "win_rate = sum(score > 0.8 for score in similarity_scores) / len(similarity_scores) if len(similarity_scores) > 0 else 0\n",
    "\n",
    "# Calculate top-1, top-5, and top-10 average scores for the model\n",
    "sorted_scores = sorted(similarity_scores, reverse=True)\n",
    "top_1_score = sorted_scores[0] if len(sorted_scores) >= 1 else 0\n",
    "top_5_average = sum(sorted_scores[:5]) / 5 if len(sorted_scores) >= 5 else 0\n",
    "top_10_average = sum(sorted_scores[:10]) / 10 if len(sorted_scores) >= 10 else 0\n",
    "\n",
    "# Calculate win rate for GPT-4\n",
    "gpt_win_rate = sum(score > 0.8 for score in gpt_scores_list) / len(gpt_scores_list) if len(gpt_scores_list) > 0 else 0\n",
    "\n",
    "# Calculate top-1, top-5, and top-10 average scores for GPT-4\n",
    "gsorted_scores = sorted(gpt_scores_list, reverse=True)\n",
    "gtop_1_score = gsorted_scores[0] if len(gsorted_scores) >= 1 else 0\n",
    "gtop_5_average = sum(gsorted_scores[:5]) / 5 if len(gsorted_scores) >= 5 else 0\n",
    "gtop_10_average = sum(gsorted_scores[:10]) / 10 if len(gsorted_scores) >= 10 else 0\n",
    "\n",
    "# Save inference results to a file\n",
    "results_df = pd.DataFrame(valid_samples)\n",
    "results_df.to_csv('flickr30k_model_results.csv', index=False)\n",
    "\n",
    "# Save metrics to a file\n",
    "metrics_df = pd.DataFrame([{\n",
    "    \"win_rate\": win_rate,\n",
    "    \"top_1_score\": top_1_score,\n",
    "    \"top_5_average_score\": top_5_average,\n",
    "    \"top_10_average_score\": top_10_average\n",
    "}])\n",
    "metrics_df.to_csv('flickr30k_dataset_scores.csv', index=False)\n",
    "\n",
    "# Save GPT-4 metrics to a file\n",
    "gpt_metrics_df = pd.DataFrame([{\n",
    "    \"win_rate\": gpt_win_rate,\n",
    "    \"top_1_score\": gtop_1_score,\n",
    "    \"top_5_average_score\": gtop_5_average,\n",
    "    \"top_10_average_score\": gtop_10_average\n",
    "}])\n",
    "gpt_metrics_df.to_csv('flickr30k_gpt4_scores.csv', index=False)\n",
    "\n",
    "print(metrics_df)\n",
    "print(gpt_metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
